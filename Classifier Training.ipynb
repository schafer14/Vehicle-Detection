{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import progressbar\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_image_directory = \"../data/vehicles\"\n",
    "non_vehicle_image_directory = \"../data/non-vehicles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_files = glob.glob(vehicle_image_directory + '/**/*.png')\n",
    "non_vehicle_files = glob.glob(non_vehicle_image_directory + '/**/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features\n",
    "\n",
    "The raw pixel intensities of the saturation channel shouldn't be helpful because of ordering, but for what ever reason seem to help the model. I'm leaving it in beacuse I'm superstitous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    orient = 9\n",
    "    pixels_per_cell = (8, 8)\n",
    "    cell_per_block = (2, 2)\n",
    "\n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    h1 = hog(HSV[:,:,0], orientations=orient, pixels_per_cell=pixels_per_cell, transform_sqrt=True, cells_per_block=cell_per_block)\n",
    "    h2 = hog(HSV[:,:,1], orientations=orient, pixels_per_cell=pixels_per_cell, transform_sqrt=True, cells_per_block=cell_per_block)\n",
    "    h3 = hog(HSV[:,:,2], orientations=orient, pixels_per_cell=pixels_per_cell, transform_sqrt=True, cells_per_block=cell_per_block)\n",
    "#     channel1_hist, _ = np.histogram(img[:,:,0], bins=32)\n",
    "#     channel2_hist, _ = np.histogram(img[:,:,1], bins=32)\n",
    "#     channel3_hist, _ = np.histogram(img[:,:,2], bins=32)\n",
    "    \n",
    "    return np.concatenate((h1, h2, h3, HSV[:, :, 1].ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 8792) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/home/banner/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n",
      "  0% (9 of 8792) |                         | Elapsed Time: 0:00:00 ETA: 0:01:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CAR IMAGES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8792 of 8792) |#####################| Elapsed Time: 0:00:39 Time: 0:00:39\n",
      "  0% (13 of 8968) |                        | Elapsed Time: 0:00:00 ETA: 0:01:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING NON CAR IMAGES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8968 of 8968) |#####################| Elapsed Time: 0:00:39 Time: 0:00:39\n"
     ]
    }
   ],
   "source": [
    "print(\"LOADING CAR IMAGES\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "for file in bar(vehicle_files):\n",
    "    img = cv2.imread(file)\n",
    "    features = extract_features(img)\n",
    "    data.append(features)\n",
    "    labels.append(1)\n",
    "    \n",
    "print(\"LOADING NON CAR IMAGES\")\n",
    "bar = progressbar.ProgressBar()\n",
    "for file in bar(non_vehicle_files):\n",
    "    img = cv2.imread(file)\n",
    "    features = extract_features(img)\n",
    "    data.append(features)\n",
    "    labels.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize model and we will save the normalizer later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17760, 9388)\n",
      "17760\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack(data).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "X, y = shuffle(scaled_X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training validation and test data sets \n",
    "\n",
    "We use the validation set before the hard negative mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_test, y_1, y_test = train_test_split(X, y, test_size=0.33)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_1, y_1, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model on training set adn predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.4, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(probability=True, C=.4, kernel=\"linear\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_validation, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.981920040744\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find examples for the validation set that were false positives and add them back into the training sets as hard negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = []\n",
    "nn = 0\n",
    "for i, (pred, truth) in enumerate(zip(preds, y_validation)):\n",
    "    if pred == 1 and truth ==  -1:\n",
    "        negatives.append(i)\n",
    "    else:\n",
    "        nn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = np.concatenate([X_train, X_validation[negatives]], axis=0)\n",
    "new_y = np.concatenate([np.array(y_train), np.array(y_validation)[negatives]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain model with hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.4, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report accuracy of predictions on test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.985326736052\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Test accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model along with the normalizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"classifier.pkl\", \"wb\")\n",
    "cPickle.dump(model, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"normalizer.pkl\", \"wb\")\n",
    "cPickle.dump(X_scaler, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
